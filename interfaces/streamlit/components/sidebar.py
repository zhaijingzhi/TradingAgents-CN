"""
ä¾§è¾¹æ ç»„ä»¶
"""

import streamlit as st
import os
from interfaces.streamlit.utils.model_config_manager import model_config_manager

def render_sidebar():
    """æ¸²æŸ“ä¾§è¾¹æ é…ç½®"""

    with st.sidebar:
        # æ·»åŠ ä¾§è¾¹æ æ ‡é¢˜å’ŒçŠ¶æ€æŒ‡ç¤º
        st.markdown("# ğŸ¤– TradingAgents-CN")
        
        # æ·»åŠ å½“å‰é¡µé¢æŒ‡ç¤º
        current_page = st.session_state.get('page_selector', 'ğŸ“Š ä»ªè¡¨æ¿')
        st.markdown(f"**å½“å‰é¡µé¢**: {current_page}")
        st.markdown("---")
        # é¡µé¢å¯¼èˆª
        st.markdown("### ğŸ“‹ åŠŸèƒ½å¯¼èˆª")
        
        # é¡µé¢é€‰é¡¹
        page_options = [
            "ğŸ“Š ä»ªè¡¨æ¿", 
            "ğŸ“ˆ è‚¡ç¥¨åˆ†æ", 
            "ğŸ’¼ æŠ•èµ„ç»„åˆ", 
            "ğŸ“‹ åˆ†æå†å²", 
            "ğŸ“Š å¸‚åœºç›‘æ§",
            "ğŸ¤– æ¨¡å‹é…ç½®", 
            "âš™ï¸ ç³»ç»Ÿè®¾ç½®",
            "ğŸ’¾ ç¼“å­˜ç®¡ç†", 
            "ğŸ’° Tokenç»Ÿè®¡"
        ]
        
        # é¡µé¢æ˜ å°„
        page_mapping = {
            "stock_analysis": "ğŸ“ˆ è‚¡ç¥¨åˆ†æ",
            "model_config": "ğŸ¤– æ¨¡å‹é…ç½®", 
            "analysis_history": "ğŸ“‹ åˆ†æå†å²",
            "system_settings": "âš™ï¸ ç³»ç»Ÿè®¾ç½®",
            "portfolio_management": "ğŸ’¼ æŠ•èµ„ç»„åˆ",
            "market_monitor": "ğŸ“Š å¸‚åœºç›‘æ§",
            "cache_management": "ğŸ’¾ ç¼“å­˜ç®¡ç†",
            "token_statistics": "ğŸ’° Tokenç»Ÿè®¡"
        }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ¥è‡ªå…¶ä»–é¡µé¢çš„è·³è½¬è¯·æ±‚
        current_page_from_state = st.session_state.get('current_page')
        if current_page_from_state and current_page_from_state in page_mapping:
            target_page = page_mapping[current_page_from_state]
            # è®¾ç½®é€‰æ‹©å™¨çš„å€¼
            st.session_state.page_selector = target_page
            # æ¸…é™¤è·³è½¬çŠ¶æ€ï¼Œé¿å…é‡å¤è·³è½¬
            st.session_state.current_page = None
        
        # å¤„ç†æ¥è‡ªquery paramsçš„target_pageå¯¼èˆª
        if 'target_page' in st.session_state:
            st.session_state.page_selector = st.session_state.target_page
            # æ¸…é™¤target_pageé¿å…é‡å¤è§¦å‘
            del st.session_state.target_page
        
        # è·å–å½“å‰é€‰æ‹©çš„é¡µé¢
        if 'page_selector' not in st.session_state:
            st.session_state.page_selector = "ğŸ“Š ä»ªè¡¨æ¿"
        
        # è·å–é»˜è®¤ç´¢å¼•
        try:
            default_index = page_options.index(st.session_state.page_selector)
        except ValueError:
            default_index = 0
            st.session_state.page_selector = page_options[0]
        
        page = st.selectbox(
            "é€‰æ‹©åŠŸèƒ½æ¨¡å—",
            page_options,
            index=default_index,
            help="é€‰æ‹©è¦ä½¿ç”¨çš„åŠŸèƒ½æ¨¡å—",
            key="page_selector"
        )
        
        st.markdown("---")
        
        # æ·»åŠ å¿«é€Ÿå¯¼èˆªæŒ‰é’®ï¼ˆåœ¨æ‰€æœ‰é¡µé¢éƒ½æ˜¾ç¤ºï¼‰
        st.markdown("### ğŸš€ å¿«é€Ÿæ“ä½œ")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“ˆ å¿«é€Ÿåˆ†æ", use_container_width=True, help="å¿«é€Ÿå¼€å§‹è‚¡ç¥¨åˆ†æ"):
                st.session_state.page_selector = "ğŸ“ˆ è‚¡ç¥¨åˆ†æ"
                st.rerun()
        
        with col2:
            if st.button("ğŸ“‹ æŸ¥çœ‹å†å²", use_container_width=True, help="æŸ¥çœ‹åˆ†æå†å²"):
                st.session_state.page_selector = "ğŸ“‹ åˆ†æå†å²"
                st.rerun()
        
        # å¦‚æœä¸æ˜¯è‚¡ç¥¨åˆ†æé¡µé¢ï¼Œæ˜¾ç¤ºç®€åŒ–çš„ä¾§è¾¹æ å¹¶è¿”å›é¡µé¢ä¿¡æ¯
        if page != "ğŸ“ˆ è‚¡ç¥¨åˆ†æ":
            render_simplified_sidebar()
            return {"page": page}

        # æ˜¾ç¤ºå½“å‰æ¨¡å‹çŠ¶æ€
        st.markdown("### ğŸ¤– å½“å‰æ¨¡å‹")
        current_model_name = model_config_manager.get_current_model()
        current_model = model_config_manager.get_model_config(current_model_name)
        
        if current_model and current_model.is_available:
            st.success(f"âœ… {current_model.display_name}")
            # è·å–åˆ†æé…ç½®
            model_analysis_config = model_config_manager.get_model_for_analysis(current_model_name)
            llm_provider = model_analysis_config.get("llm_provider", "anthropic")
            deep_think_llm = model_analysis_config.get("deep_think_llm", "claude-3-5-sonnet-20241022")
            quick_think_llm = model_analysis_config.get("quick_think_llm", "claude-3-5-haiku-20241022")
            backend_url = model_analysis_config.get("backend_url", "https://anyrouter.top")
            
            # æ˜¾ç¤ºæ¨¡å‹è¯¦æƒ…
            with st.expander("ğŸ“‹ æ¨¡å‹è¯¦æƒ…", expanded=False):
                st.info(f"**æ·±åº¦æ€è€ƒ**: `{deep_think_llm}`")
                st.info(f"**å¿«é€Ÿæ€è€ƒ**: `{quick_think_llm}`")
                st.info(f"**APIç«¯ç‚¹**: `{backend_url}`")
        else:
            st.error("âŒ å½“å‰æ¨¡å‹ä¸å¯ç”¨")
            st.warning("è¯·åœ¨æ¨¡å‹é…ç½®é¡µé¢è®¾ç½®å¯ç”¨çš„æ¨¡å‹")
        
        # å¿«é€Ÿåˆ‡æ¢åˆ°æ¨¡å‹é…ç½®
        if st.button("âš™ï¸ é…ç½®æ¨¡å‹", help="åˆ‡æ¢åˆ°æ¨¡å‹é…ç½®é¡µé¢", use_container_width=True):
            return {"page": "ğŸ¤– æ¨¡å‹é…ç½®"}

        # AIæ¨¡å‹é…ç½® (ä¿æŒå…¼å®¹æ€§)
        st.markdown("### ğŸ§  AIæ¨¡å‹é…ç½®")

        # LLMæä¾›å•†é€‰æ‹© - ä»session stateè·å–å½“å‰é…ç½®
        current_config = st.session_state.get('sidebar_config', {})
        current_provider = current_config.get('llm_provider', 'dashscope')
        
        provider_options = ["dashscope", "deepseek", "google"]
        try:
            provider_index = provider_options.index(current_provider)
        except ValueError:
            provider_index = 0
        
        llm_provider = st.selectbox(
            "LLMæä¾›å•†",
            options=provider_options,
            index=provider_index,
            format_func=lambda x: {
                "dashscope": "é˜¿é‡Œç™¾ç‚¼",
                "deepseek": "DeepSeek V3",
                "google": "Google AI"
            }[x],
            help="é€‰æ‹©AIæ¨¡å‹æä¾›å•†",
            key="sidebar_llm_provider"
        )

        # æ ¹æ®æä¾›å•†æ˜¾ç¤ºä¸åŒçš„æ¨¡å‹é€‰é¡¹
        current_model = current_config.get('llm_model', '')
        
        if llm_provider == "dashscope":
            dashscope_options = ["qwen-turbo", "qwen-plus-latest", "qwen-max"]
            try:
                model_index = dashscope_options.index(current_model) if current_model in dashscope_options else 1
            except ValueError:
                model_index = 1
                
            llm_model = st.selectbox(
                "æ¨¡å‹ç‰ˆæœ¬",
                options=dashscope_options,
                index=model_index,
                format_func=lambda x: {
                    "qwen-turbo": "Turbo - å¿«é€Ÿ",
                    "qwen-plus-latest": "Plus - å¹³è¡¡",
                    "qwen-max": "Max - æœ€å¼º"
                }[x],
                help="é€‰æ‹©ç”¨äºåˆ†æçš„é˜¿é‡Œç™¾ç‚¼æ¨¡å‹",
                key="sidebar_dashscope_model"
            )
        elif llm_provider == "deepseek":
            deepseek_options = ["deepseek-chat"]
            try:
                model_index = deepseek_options.index(current_model) if current_model in deepseek_options else 0
            except ValueError:
                model_index = 0
                
            llm_model = st.selectbox(
                "é€‰æ‹©DeepSeekæ¨¡å‹",
                options=deepseek_options,
                index=model_index,
                format_func=lambda x: {
                    "deepseek-chat": "DeepSeek Chat - é€šç”¨å¯¹è¯æ¨¡å‹ï¼Œé€‚åˆè‚¡ç¥¨åˆ†æ"
                }[x],
                help="é€‰æ‹©ç”¨äºåˆ†æçš„DeepSeekæ¨¡å‹",
                key="sidebar_deepseek_model"
            )
        else:  # google
            google_options = ["gemini-2.0-flash", "gemini-1.5-pro", "gemini-1.5-flash"]
            try:
                model_index = google_options.index(current_model) if current_model in google_options else 0
            except ValueError:
                model_index = 0
                
            llm_model = st.selectbox(
                "é€‰æ‹©Googleæ¨¡å‹",
                options=google_options,
                index=model_index,
                format_func=lambda x: {
                    "gemini-2.0-flash": "Gemini 2.0 Flash - æ¨èä½¿ç”¨",
                    "gemini-1.5-pro": "Gemini 1.5 Pro - å¼ºå¤§æ€§èƒ½",
                    "gemini-1.5-flash": "Gemini 1.5 Flash - å¿«é€Ÿå“åº”"
                }[x],
                help="é€‰æ‹©ç”¨äºåˆ†æçš„Google Geminiæ¨¡å‹",
                key="sidebar_google_model"
            )
        
        # é«˜çº§è®¾ç½®
        with st.expander("âš™ï¸ é«˜çº§è®¾ç½®"):
            enable_memory = st.checkbox(
                "å¯ç”¨è®°å¿†åŠŸèƒ½",
                value=False,
                help="å¯ç”¨æ™ºèƒ½ä½“è®°å¿†åŠŸèƒ½ï¼ˆå¯èƒ½å½±å“æ€§èƒ½ï¼‰"
            )
            
            enable_debug = st.checkbox(
                "è°ƒè¯•æ¨¡å¼",
                value=False,
                help="å¯ç”¨è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯è¾“å‡º"
            )
            
            max_tokens = st.slider(
                "æœ€å¤§è¾“å‡ºé•¿åº¦",
                min_value=1000,
                max_value=8000,
                value=4000,
                step=500,
                help="AIæ¨¡å‹çš„æœ€å¤§è¾“å‡ºtokenæ•°é‡"
            )
        
        st.markdown("---")

        # ç³»ç»Ÿé…ç½®
        st.markdown("**ğŸ”§ ç³»ç»Ÿé…ç½®**")

        # APIå¯†é’¥çŠ¶æ€
        st.markdown("**ğŸ”‘ APIå¯†é’¥çŠ¶æ€**")

        def validate_api_key(key, expected_format):
            """éªŒè¯APIå¯†é’¥æ ¼å¼"""
            if not key:
                return "æœªé…ç½®", "error"

            if expected_format == "dashscope" and key.startswith("sk-") and len(key) >= 32:
                return f"{key[:8]}...", "success"
            elif expected_format == "deepseek" and key.startswith("sk-") and len(key) >= 32:
                return f"{key[:8]}...", "success"
            elif expected_format == "finnhub" and len(key) >= 20:
                return f"{key[:8]}...", "success"
            elif expected_format == "tushare" and len(key) >= 32:
                return f"{key[:8]}...", "success"
            elif expected_format == "google" and key.startswith("AIza") and len(key) >= 32:
                return f"{key[:8]}...", "success"
            elif expected_format == "openai" and key.startswith("sk-") and len(key) >= 40:
                return f"{key[:8]}...", "success"
            elif expected_format == "anthropic" and key.startswith("sk-") and len(key) >= 40:
                return f"{key[:8]}...", "success"
            elif expected_format == "reddit" and len(key) >= 10:
                return f"{key[:8]}...", "success"
            else:
                return f"{key[:8]}... (æ ¼å¼å¼‚å¸¸)", "warning"

        # å¿…éœ€çš„APIå¯†é’¥
        st.markdown("*å¿…éœ€é…ç½®:*")

        # é˜¿é‡Œç™¾ç‚¼
        dashscope_key = os.getenv("DASHSCOPE_API_KEY")
        status, level = validate_api_key(dashscope_key, "dashscope")
        if level == "success":
            st.success(f"âœ… é˜¿é‡Œç™¾ç‚¼: {status}")
        elif level == "warning":
            st.warning(f"âš ï¸ é˜¿é‡Œç™¾ç‚¼: {status}")
        else:
            st.error("âŒ é˜¿é‡Œç™¾ç‚¼: æœªé…ç½®")

        # FinnHub
        finnhub_key = os.getenv("FINNHUB_API_KEY")
        status, level = validate_api_key(finnhub_key, "finnhub")
        if level == "success":
            st.success(f"âœ… FinnHub: {status}")
        elif level == "warning":
            st.warning(f"âš ï¸ FinnHub: {status}")
        else:
            st.error("âŒ FinnHub: æœªé…ç½®")

        # å¯é€‰çš„APIå¯†é’¥
        st.markdown("*å¯é€‰é…ç½®:*")

        # DeepSeek
        deepseek_key = os.getenv("DEEPSEEK_API_KEY")
        status, level = validate_api_key(deepseek_key, "deepseek")
        if level == "success":
            st.success(f"âœ… DeepSeek: {status}")
        elif level == "warning":
            st.warning(f"âš ï¸ DeepSeek: {status}")
        else:
            st.info("â„¹ï¸ DeepSeek: æœªé…ç½®")

        # Tushare
        tushare_key = os.getenv("TUSHARE_TOKEN")
        status, level = validate_api_key(tushare_key, "tushare")
        if level == "success":
            st.success(f"âœ… Tushare: {status}")
        elif level == "warning":
            st.warning(f"âš ï¸ Tushare: {status}")
        else:
            st.info("â„¹ï¸ Tushare: æœªé…ç½®")

        # Google AI
        google_key = os.getenv("GOOGLE_API_KEY")
        status, level = validate_api_key(google_key, "google")
        if level == "success":
            st.success(f"âœ… Google AI: {status}")
        elif level == "warning":
            st.warning(f"âš ï¸ Google AI: {status}")
        else:
            st.info("â„¹ï¸ Google AI: æœªé…ç½®")

        # OpenAI (å¦‚æœé…ç½®äº†ä¸”ä¸æ˜¯é»˜è®¤å€¼)
        openai_key = os.getenv("OPENAI_API_KEY")
        if openai_key and openai_key != "your_openai_api_key_here":
            status, level = validate_api_key(openai_key, "openai")
            if level == "success":
                st.success(f"âœ… OpenAI: {status}")
            elif level == "warning":
                st.warning(f"âš ï¸ OpenAI: {status}")

        # Anthropic (å¦‚æœé…ç½®äº†ä¸”ä¸æ˜¯é»˜è®¤å€¼)
        anthropic_key = os.getenv("ANTHROPIC_API_KEY")
        if anthropic_key and anthropic_key != "your_anthropic_api_key_here":
            status, level = validate_api_key(anthropic_key, "anthropic")
            if level == "success":
                st.success(f"âœ… Anthropic: {status}")
            elif level == "warning":
                st.warning(f"âš ï¸ Anthropic: {status}")

        st.markdown("---")

        # ç³»ç»Ÿä¿¡æ¯
        st.markdown("**â„¹ï¸ ç³»ç»Ÿä¿¡æ¯**")
        
        st.info(f"""
        **ç‰ˆæœ¬**: 1.0.0
        **æ¡†æ¶**: Streamlit + LangGraph
        **AIæ¨¡å‹**: {llm_provider.upper()} - {llm_model}
        **æ•°æ®æº**: Tushare + FinnHub API
        """)
        
        # å¸®åŠ©é“¾æ¥
        st.markdown("**ğŸ“š å¸®åŠ©èµ„æº**")
        
        st.markdown("""
        - [ğŸ“– ä½¿ç”¨æ–‡æ¡£](https://github.com/TauricResearch/TradingAgents)
        - [ğŸ› é—®é¢˜åé¦ˆ](https://github.com/TauricResearch/TradingAgents/issues)
        - [ğŸ’¬ è®¨è®ºç¤¾åŒº](https://github.com/TauricResearch/TradingAgents/discussions)
        - [ğŸ”§ APIå¯†é’¥é…ç½®](../docs/security/api_keys_security.md)
        """)
    
    return {
        'llm_provider': llm_provider,
        'llm_model': llm_model,
        'enable_memory': enable_memory,
        'enable_debug': enable_debug,
        'max_tokens': max_tokens
    }

def render_simplified_sidebar():
    """æ¸²æŸ“ç®€åŒ–çš„ä¾§è¾¹æ ï¼ˆç”¨äºéè‚¡ç¥¨åˆ†æé¡µé¢ï¼‰"""
    
    # æ˜¾ç¤ºå½“å‰æ¨¡å‹çŠ¶æ€
    st.markdown("### ğŸ¤– å½“å‰æ¨¡å‹")
    current_model_name = model_config_manager.get_current_model()
    current_model = model_config_manager.get_model_config(current_model_name)
    
    if current_model and current_model.is_available:
        st.success(f"âœ… {current_model.display_name}")
        
        # æ˜¾ç¤ºç®€åŒ–çš„æ¨¡å‹ä¿¡æ¯
        with st.expander("ğŸ“‹ æ¨¡å‹ä¿¡æ¯", expanded=False):
            model_analysis_config = model_config_manager.get_model_for_analysis(current_model_name)
            llm_provider = model_analysis_config.get("llm_provider", "anthropic")
            deep_think_llm = model_analysis_config.get("deep_think_llm", "claude-3-5-sonnet-20241022")
            st.info(f"**æä¾›å•†**: {llm_provider}")
            st.info(f"**æ¨¡å‹**: {deep_think_llm}")
    else:
        st.error("âŒ å½“å‰æ¨¡å‹ä¸å¯ç”¨")
        st.warning("è¯·åœ¨æ¨¡å‹é…ç½®é¡µé¢è®¾ç½®å¯ç”¨çš„æ¨¡å‹")
    
    # å¿«é€Ÿåˆ‡æ¢åˆ°æ¨¡å‹é…ç½®
    if st.button("âš™ï¸ é…ç½®æ¨¡å‹", help="åˆ‡æ¢åˆ°æ¨¡å‹é…ç½®é¡µé¢", use_container_width=True, key="simplified_config_model"):
        st.session_state.page_selector = "ğŸ¤– æ¨¡å‹é…ç½®"
        st.rerun()
    
    st.markdown("---")
    
    # æ˜¾ç¤ºç®€åŒ–çš„APIçŠ¶æ€
    st.markdown("### ğŸ”‘ APIçŠ¶æ€")
    
    # æ£€æŸ¥å…³é”®APIå¯†é’¥
    api_keys = {
        "é˜¿é‡Œç™¾ç‚¼": os.getenv("DASHSCOPE_API_KEY"),
        "DeepSeek": os.getenv("DEEPSEEK_API_KEY"),
        "Tushare": os.getenv("TUSHARE_TOKEN"),
        "FinnHub": os.getenv("FINNHUB_API_KEY")
    }
    
    configured_count = 0
    for name, key in api_keys.items():
        if key and key not in ["your_finnhub_api_key_here", "your_deepseek_api_key_here"]:
            configured_count += 1
    
    if configured_count >= 2:  # è‡³å°‘é…ç½®äº†2ä¸ªAPIå¯†é’¥
        st.success(f"âœ… {configured_count}/{len(api_keys)} ä¸ªAPIå·²é…ç½®")
    elif configured_count >= 1:
        st.warning(f"âš ï¸ {configured_count}/{len(api_keys)} ä¸ªAPIå·²é…ç½®")
    else:
        st.error(f"âŒ {configured_count}/{len(api_keys)} ä¸ªAPIå·²é…ç½®")
    
    # å¿«é€Ÿè·³è½¬åˆ°ç³»ç»Ÿè®¾ç½®
    if st.button("âš™ï¸ ç³»ç»Ÿè®¾ç½®", help="æŸ¥çœ‹è¯¦ç»†APIçŠ¶æ€å’Œç³»ç»Ÿé…ç½®", use_container_width=True, key="simplified_system_settings"):
        st.session_state.page_selector = "âš™ï¸ ç³»ç»Ÿè®¾ç½®"
        st.rerun()
    
    st.markdown("---")
    
    # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
    st.markdown("### â„¹ï¸ ç³»ç»Ÿä¿¡æ¯")
    
    # è·å–å½“å‰é…ç½®
    current_config = st.session_state.get('sidebar_config', {})
    llm_provider = current_config.get('llm_provider', 'dashscope')
    llm_model = current_config.get('llm_model', 'qwen-plus-latest')
    
    st.info(f"""
    **ç‰ˆæœ¬**: cn-0.1.10
    **å½“å‰æ¨¡å‹**: {llm_provider.upper()}
    **æ¡†æ¶**: Streamlit + LangGraph
    """)
    
    # å¸®åŠ©é“¾æ¥
    st.markdown("### ğŸ“š å¿«é€Ÿé“¾æ¥")
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ“– ä½¿ç”¨æ–‡æ¡£", use_container_width=True, key="simplified_docs"):
            st.markdown("[ğŸ“– æŸ¥çœ‹æ–‡æ¡£](https://github.com/hsliuping/TradingAgents-CN)")
    
    with col2:
        if st.button("ğŸ› é—®é¢˜åé¦ˆ", use_container_width=True, key="simplified_issues"):
            st.markdown("[ğŸ› æäº¤é—®é¢˜](https://github.com/hsliuping/TradingAgents-CN/issues)")
